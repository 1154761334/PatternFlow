{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 1816\n",
      "Size of validation set: 389\n",
      "2594\n",
      "2594\n",
      "2594\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "masks = sorted(glob.glob(\"D:/ISIC2018_Task1_Training_GroundTruth_x2/*.png\"))\n",
    "files = sorted(glob.glob(\"D:/ISIC2018_Task1-2_Training_Input_x2/*.jpg\"))\n",
    "\n",
    "num_images = len(masks)\n",
    "\n",
    "val_test_size = int(num_images*0.3)\n",
    "\n",
    "val_test_images = files[:val_test_size]\n",
    "train_images = files[val_test_size:]\n",
    "val_test_masks = masks[:val_test_size]\n",
    "train_masks = masks[val_test_size:]\n",
    "\n",
    "split = int(len(val_test_masks)*0.5)\n",
    "val_masks = val_test_masks[split:]\n",
    "val_images = val_test_images[split:]\n",
    "test_masks = val_test_masks[:split]\n",
    "test_images = val_test_images[:split]\n",
    "\n",
    "print('Size of training set:', len(train_images))\n",
    "print('Size of validation set:', len(val_images))\n",
    "\n",
    "\n",
    "print(len(val_masks)+len(test_masks)+len(train_masks))\n",
    "print(len(val_images)+len(test_images)+len(train_images))\n",
    "print(len(masks))\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_images, train_masks))\n",
    "val_data = tf.data.Dataset.from_tensor_slices((val_images, val_masks))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_images, test_masks))\n",
    "\n",
    "#for image, mask in train_data.take(1):\n",
    "#    print(image)\n",
    "\n",
    "#shuffling data\n",
    "train_data = train_data.shuffle(len(train_images))\n",
    "val_data = val_data.shuffle(len(val_images))\n",
    "test_data = test_data.shuffle(len(test_images))\n",
    "\n",
    "def map_fn(image_fp, mask_fp):\n",
    "    image = tf.io.read_file(image_fp)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (256, 256))\n",
    "    image = tf.cast(image, tf.float32) /255.0\n",
    "    \n",
    "    mask = tf.io.read_file(mask_fp)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, (256, 256))\n",
    "    mask = mask == [0, 255]\n",
    "    mask = tf.cast(mask, tf.uint8)\n",
    "    return image, mask\n",
    "\n",
    "train_data = train_data.map(map_fn)\n",
    "val_data = val_data.map(map_fn)\n",
    "test_data = test_data.map(map_fn)\n",
    "\n",
    "def display(display_list):\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.imshow(display_list[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "for image, mask in train_data.take(1):\n",
    "    display([tf.squeeze(image), tf.argmax(mask, axis=-1)])\n",
    "    \n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + tf.keras.backend.epsilon()) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f)\n",
    "                                                               + tf.keras.backend.epsilon())\n",
    "\n",
    "def unet_model(output_channels, f = 64):\n",
    "    inputs = tf.keras.layers.Input(shape=(512, 512, 3))\n",
    "    \n",
    "    d1 = tf.keras.layers.Conv2D(f, 3, padding='same', activation='relu')(inputs)\n",
    "    d1 = tf.keras.layers.Conv2D(f, 3, padding='same', activation='relu')(d1)\n",
    "    \n",
    "    d2 = tf.keras.layers.MaxPooling2D()(d1)\n",
    "    d2 = tf.keras.layers.Conv2D(2*f, 3, padding='same', activation='relu')(d2)\n",
    "    d2 = tf.keras.layers.Conv2D(2*f, 3, padding='same', activation='relu')(d2)\n",
    "    \n",
    "    d3 = tf.keras.layers.MaxPooling2D()(d2)\n",
    "    d3 = tf.keras.layers.Conv2D(4*f, 3, padding='same', activation='relu')(d3)\n",
    "    d3 = tf.keras.layers.Conv2D(4*f, 3, padding='same', activation='relu')(d3)\n",
    "    \n",
    "    d4 = tf.keras.layers.MaxPooling2D()(d3)\n",
    "    d4 = tf.keras.layers.Conv2D(8*f, 3, padding='same', activation='relu')(d4)\n",
    "    d4 = tf.keras.layers.Conv2D(8*f, 3, padding='same', activation='relu')(d4)\n",
    "    \n",
    "    d5 = tf.keras.layers.MaxPooling2D()(d4)\n",
    "    d5 = tf.keras.layers.Conv2D(16*f, 3, padding='same', activation='relu')(d5)\n",
    "    d5 = tf.keras.layers.Conv2D(16*f, 3, padding='same', activation='relu')(d5)\n",
    "    \n",
    "    u4 = tf.keras.layers.UpSampling2D()(d5)\n",
    "    u4 = tf.keras.layers.concatenate([u4, d4])\n",
    "    u4 = tf.keras.layers.Conv2D(8*f, 3, padding='same', activation='relu')(u4)\n",
    "    u4 = tf.keras.layers.Conv2D(8*f, 3, padding='same', activation='relu')(u4)\n",
    "    \n",
    "    u3 = tf.keras.layers.UpSampling2D()(u4) \n",
    "    u3 = tf.keras.layers.concatenate([u3, d3])\n",
    "    u3 = tf.keras.layers.Conv2D(4*f, 3, padding ='same', activation='relu')(u3)\n",
    "    u3 = tf.keras.layers.Conv2D(4*f, 3, padding ='same', activation='relu')(u3)\n",
    "    \n",
    "    u2 = tf.keras.layers.UpSampling2D()(u3) \n",
    "    u2 = tf.keras.layers.concatenate([u2, d2])\n",
    "    u2 = tf.keras.layers.Conv2D(2*f, 3, padding ='same', activation='relu')(u2)\n",
    "    u2 = tf.keras.layers.Conv2D(2*f, 3, padding ='same', activation='relu')(u2)\n",
    "    \n",
    "    u1 = tf.keras.layers.UpSampling2D()(u2) \n",
    "    u1 = tf.keras.layers.concatenate([u1, d1])\n",
    "    u1 = tf.keras.layers.Conv2D(f, 3, padding ='same', activation='relu')(u1)\n",
    "    u1 = tf.keras.layers.Conv2D(f, 3, padding ='same', activation='relu')(u1)\n",
    "    \n",
    "    #last layer\n",
    "    outputs = tf.keras.layers.Conv2D(output_channels, 1, activation='softmax')(u1)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model = unet_model(2, f=4)\n",
    "model.compile(optimizer='adam',\n",
    "             loss ='categorical_crossentropy',\n",
    "             metrics=[dice_coef, 'accuracy'])\n",
    "\n",
    "def show_predictions(ds, num=1):\n",
    "    for image, mask in ds.take(num):\n",
    "        pred_mask = model.predict(image[tf.newaxis, ...])\n",
    "        pred_mask = tf.argmax(pred_mask[0], axis=-1)\n",
    "        display([tf.squeeze(image), tf.argmax(mask, axis=-1), pred_mask])\n",
    "    \n",
    "show_predictions(val_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
