{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental.preprocessing'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8a27db668615>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     raise ImportError(\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[1;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "\n",
    "#Dataset downloaded and unzipped on D drive\n",
    "train_images = sorted(glob.glob(\"D:/keras_png_slices_data/keras_png_slices_train/*.png\"))\n",
    "train_masks = sorted(glob.glob(\"D:/keras_png_slices_data/keras_png_slices_seg_train/*.png\"))\n",
    "val_images = sorted(glob.glob(\"D:/keras_png_slices_data/keras_png_slices_validate/*.png\"))\n",
    "val_masks = sorted(glob.glob(\"D:/keras_png_slices_data/keras_png_slices_seg_validate/*.png\"))\n",
    "test_images = sorted(glob.glob(\"D:/keras_png_slices_data/keras_png_slices_test/*.png\"))\n",
    "test_masks = sorted(glob.glob(\"D:/keras_png_slices_data/keras_png_slices_seg_test/*.png\"))\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_images, train_masks))\n",
    "val_data = tf.data.Dataset.from_tensor_slices((val_images, val_masks))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_images, test_masks))\n",
    "train_data = train_data.shuffle(len(train_images))\n",
    "val_data = val_data.shuffle(len(val_images))\n",
    "test_data = test_data.shuffle(len(test_images))\n",
    "\n",
    "\n",
    "def map_fn(image_fp, mask_fp):\n",
    "    image = tf.io.read_file(image_fp)\n",
    "    image = tf.image.decode_png(image, channels=1)\n",
    "    image = tf.image.resize(image, (256, 256))\n",
    "    image = tf.cast(image, tf.float32) /255.0\n",
    "    \n",
    "    mask = tf.io.read_file(mask_fp)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, (256, 256))\n",
    "    mask = mask == [0, 85, 170, 255]\n",
    "    mask = tf.cast(mask, tf.uint8)\n",
    "    return image, mask\n",
    "\n",
    "def display(display_list):\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.imshow(display_list[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "train_data = train_data.map(map_fn)\n",
    "val_data = val_data.map(map_fn)\n",
    "test_data = test_data.map(map_fn)\n",
    "\n",
    "\n",
    "#Must reference for later on\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + tf.keras.backend.epsilon()) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f)\n",
    "                                                               + tf.keras.backend.epsilon())\n",
    "\n",
    "#unet model\n",
    "\n",
    "def unet_model(output_channels, f = 64):\n",
    "    inputs = tf.keras.layers.Input(shape=(256, 256, 1))\n",
    "    \n",
    "    d1 = tf.keras.layers.Conv2D(f, 3, padding='same', activation='relu')(inputs)\n",
    "    d1 = tf.keras.layers.Conv2D(f, 3, padding='same', activation='relu')(d1)\n",
    "    \n",
    "    d2 = tf.keras.layers.MaxPooling2D()(d1)\n",
    "    d2 = tf.keras.layers.Conv2D(2*f, 3, padding='same', activation='relu')(d2)\n",
    "    d2 = tf.keras.layers.Conv2D(2*f, 3, padding='same', activation='relu')(d2)\n",
    "    \n",
    "    d3 = tf.keras.layers.MaxPooling2D()(d2)\n",
    "    d3 = tf.keras.layers.Conv2D(4*f, 3, padding='same', activation='relu')(d3)\n",
    "    d3 = tf.keras.layers.Conv2D(4*f, 3, padding='same', activation='relu')(d3)\n",
    "    \n",
    "    d4 = tf.keras.layers.MaxPooling2D()(d3)\n",
    "    d4 = tf.keras.layers.Conv2D(8*f, 3, padding='same', activation='relu')(d4)\n",
    "    d4 = tf.keras.layers.Conv2D(8*f, 3, padding='same', activation='relu')(d4)\n",
    "    \n",
    "    d5 = tf.keras.layers.MaxPooling2D()(d4)\n",
    "    d5 = tf.keras.layers.Conv2D(16*f, 3, padding='same', activation='relu')(d5)\n",
    "    d5 = tf.keras.layers.Conv2D(16*f, 3, padding='same', activation='relu')(d5)\n",
    "    \n",
    "    u4 = tf.keras.layers.UpSampling2D()(d5)\n",
    "    u4 = tf.keras.layers.concatenate([u4, d4])\n",
    "    u4 = tf.keras.layers.Conv2D(8*f, 3, padding='same', activation='relu')(u4)\n",
    "    u4 = tf.keras.layers.Conv2D(8*f, 3, padding='same', activation='relu')(u4)\n",
    "    \n",
    "    u3 = tf.keras.layers.UpSampling2D()(u4) \n",
    "    u3 = tf.keras.layers.concatenate([u3, d3])\n",
    "    u3 = tf.keras.layers.Conv2D(4*f, 3, padding ='same', activation='relu')(u3)\n",
    "    u3 = tf.keras.layers.Conv2D(4*f, 3, padding ='same', activation='relu')(u3)\n",
    "    \n",
    "    u2 = tf.keras.layers.UpSampling2D()(u3) \n",
    "    u2 = tf.keras.layers.concatenate([u2, d2])\n",
    "    u2 = tf.keras.layers.Conv2D(2*f, 3, padding ='same', activation='relu')(u2)\n",
    "    u2 = tf.keras.layers.Conv2D(2*f, 3, padding ='same', activation='relu')(u2)\n",
    "    \n",
    "    u1 = tf.keras.layers.UpSampling2D()(u2) \n",
    "    u1 = tf.keras.layers.concatenate([u1, d1])\n",
    "    u1 = tf.keras.layers.Conv2D(f, 3, padding ='same', activation='relu')(u1)\n",
    "    u1 = tf.keras.layers.Conv2D(f, 3, padding ='same', activation='relu')(u1)\n",
    "    \n",
    "    #last layer\n",
    "    outputs = tf.keras.layers.Conv2D(output_channels, 1, activation='softmax')(u1)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model = unet_model(4, f=4)\n",
    "model.compile(optimizer='adam',\n",
    "             loss ='categorical_crossentropy',\n",
    "             metrics=[dice_coef, 'accuracy'])\n",
    "\n",
    "def show_predictions(ds, num=1):\n",
    "    for image, mask in ds.take(num):\n",
    "        pred_mask = model.predict(image[tf.newaxis, ...])\n",
    "        pred_mask = tf.argmax(pred_mask[0], axis=-1)\n",
    "        display([tf.squeeze(image), tf.argmax(mask, axis=-1), pred_mask])\n",
    "    \n",
    "show_predictions(val_data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ecff1857133c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(train_data.batch(32), epochs = 3,\n\u001b[0m\u001b[0;32m      2\u001b[0m                    validation_data = val_data.batch(32))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data.batch(32), epochs = 3,\n",
    "                   validation_data = val_data.batch(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(val_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
