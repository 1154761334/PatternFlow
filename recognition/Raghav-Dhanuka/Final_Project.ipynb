{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_for_dataset(path_train,path_seg):\n",
    "    \"\"\"This Function is used Extracting the file names of the images and masks in training, test and validation folders\"\"\"\n",
    "    \n",
    "    isic_train = next(os.walk(path_train))[2] # returns all the files \"DIR.\"\n",
    "    isic_seg_train=next(os.walk(path_seg))[2] # returns all the files \"DIR.\"\n",
    "\n",
    "    print(\"No. of images in training folder= \",len(isic_train))\n",
    "    print(\"No. of images in test folder= \",len(isic_seg_train))\n",
    "    return isic_train, isic_seg_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_test(isic_train, isic_seg_train):\n",
    "    \"\"\"This Function is used for Sorting the data with respect to labels\"\"\"\n",
    "    isic_train_sort=sorted(isic_train) # Sorting of data with respect to labels\n",
    "    isic_seg_train_sort=sorted(isic_seg_train) # Sorting of data with respect to labels\n",
    "    \n",
    "    return isic_train_sort, isic_seg_train_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_img(inp_path,isic):\n",
    "    \"\"\" This function is used for Loading the images from the Training_Input_x2 folder\"\"\"\n",
    "    \" - Storing them with the above dimensions specified\"\n",
    "    \" - Loading the images in Greayscale format\"\n",
    "    \" - Normalizing the image with 255 as Normalising data by dividing it by 255 should improve activation functions performance\"\n",
    "    \" - Sigmoid function works more efficiently with data range 0.0-1.0.\"\n",
    "    \n",
    "    X_ISIC_train= np.zeros((len(isic),img_height,img_width,1),dtype=np.float32)\n",
    "    for n, id_ in tqdm_notebook(enumerate(isic), total=len(isic)): # capture all the images ids using tqdm\n",
    "        img = load_img(inp_path+id_, color_mode = 'grayscale')  # Load images here\n",
    "        x_img = img_to_array(img) # Convert images to array\n",
    "        x_img = resize(x_img,(256,256,1),mode = 'constant',preserve_range = True)\n",
    "        X_ISIC_train[n] = x_img/255 # Normalize the images\n",
    "        \n",
    "    return X_ISIC_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_segmentation(inp_path,isic):\n",
    "    \"\"\" This function is used for Loading the images from the Training_GroundTruth_x2 folder\"\"\"\n",
    "    \" - Storing them with the above dimensions specified\"\n",
    "    \" - Loading the images in Greayscale format\"\n",
    "    \n",
    "    Y_ISIC_train= np.zeros((len(isic),img_height,img_width,1),dtype=np.uint8)\n",
    "    for n, id_ in tqdm_notebook(enumerate(isic), total=len(isic)):\n",
    "        # Load images\n",
    "        img = load_img(inp_path+id_,color_mode = 'grayscale')\n",
    "        x_img = img_to_array(img)\n",
    "        x_img = resize(x_img,(256,256,1),mode = 'constant', preserve_range = True)\n",
    "        Y_ISIC_train[n] = x_img\n",
    "        \n",
    "    return Y_ISIC_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(X_ISIC_train, Y_ISIC_train):\n",
    "    \"\"\"This Function is used for spliting the dataset into Train, Test, and Val\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_ISIC_train, Y_ISIC_train, test_size=0.20, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "    X_train.shape\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(y_train,y_test,y_val):\n",
    "    \"\"\"This Function is used for Pre_processing the Y labels into two categoraical format\"\"\"\n",
    "    \" - By calculating the quotient Normalizing the image with data range 0.0-1.0\"\n",
    "    \" - By using One-Hot Encoding to Labels\"\n",
    "    Y_ISIC_train_sc = y_train//255\n",
    "    Y_ISIC_test_sc = y_test//255\n",
    "    Y_ISIC_val_sc = y_val//255\n",
    "    Y_ISIC_train_cat = to_categorical(Y_ISIC_train_sc) # one hot encoding\n",
    "    Y_ISIC_test_cat = to_categorical(Y_ISIC_test_sc) # one hot encoding\n",
    "    Y_ISIC_val_cat = to_categorical(Y_ISIC_val_sc) # one hot encoding\n",
    "    \n",
    "    return Y_ISIC_train_cat, Y_ISIC_test_cat, Y_ISIC_val_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Dice Coeffient\n",
    "from keras import backend as K\n",
    "def dice_coeff(y_true, y_pred, smooth=1):\n",
    "    \"\"\"This Function is used to gauge similarity of two samples\"\"\"\n",
    "    \"When applied to Boolean data, using the definition of true positive (TP), false positive (FP), and false negative (FN)\"\n",
    "    \n",
    "    intersect = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersect\n",
    "    coeff_dice = K.mean((intersect + smooth) / (union + smooth), axis=0)\n",
    "    return coeff_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generat_unet():\n",
    "    \"\"\"This Function is using the improved Unet Architecture with the following changes\"\"\"\n",
    "    \" - change activation to LeakyReLU from batchnorm\"\n",
    "    \" - change dropout layer from Dropout(0.05) to Dropout(0.3)\"\n",
    "    \" - Adding two Context module with a dropout layer in between\"\n",
    "    \" - Performing the elementwise summation\"\n",
    "    \" - Downsampling the layer betweent two context module\"\n",
    "    \" - Elemetwise summation of segmentation layers\"\n",
    "    # taking input\n",
    "    inputs = Input(shape=(256, 256, 1))\n",
    "    CL = Conv2D(16, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(inputs)\n",
    "    #context module\n",
    "    CL1 = Conv2D(16, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(CL)\n",
    "    p1 = Dropout(0.3)(CL1)\n",
    "    CL1 = Conv2D(16, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(p1)\n",
    "    #element wise summation\n",
    "    CL1 = Add()([CL, CL1])\n",
    "\n",
    "    #downsampling layer between two context modules\n",
    "    CL1_ds = Conv2D(32, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same', strides=(2, 2))(CL1)\n",
    "\n",
    "    CL2 = Conv2D(32, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(CL1_ds)\n",
    "    p2 = Dropout(0.3)(CL2)\n",
    "    CL2 = Conv2D(32, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(p2)\n",
    "    \n",
    "    CL2 = Add()([CL1_ds, CL2])    \n",
    "    CL2_ds = Conv2D(64, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same', strides=(2, 2))(CL2)\n",
    "    \n",
    "    CL3 = Conv2D(64, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(CL2_ds)\n",
    "    p3 = Dropout(0.3)(CL3)\n",
    "    CL3 = Conv2D(64, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(p3)\n",
    "    \n",
    "    CL3 = Add()([CL2_ds, CL3])    \n",
    "    CL3_ds = Conv2D(128, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same', strides=(2, 2))(CL3)\n",
    "    \n",
    "    CL4 = Conv2D(128, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(CL3_ds)\n",
    "    p4 = Dropout(0.3)(CL4)\n",
    "    CL4 = Conv2D(128, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(p4)\n",
    "    \n",
    "    CL4 = Add()([CL3_ds, CL4])    \n",
    "    CL4_ds = Conv2D(256, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same', strides=(2, 2))(CL4)\n",
    "    \n",
    "    CL5 = Conv2D(256, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(CL4_ds)\n",
    "    p5 = Dropout(0.3)(CL5)\n",
    "    CL5 = Conv2D(256, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(p5)\n",
    "    \n",
    "    CL5 = Add()([CL4_ds, CL5])\n",
    "\n",
    "    L6 = UpSampling2D()(CL5)\n",
    "\n",
    "     #concatenating with corresponding downsampling layer\n",
    "    C1 = concatenate([L6, CL4])\n",
    "\n",
    "    UP1 = Conv2D(128, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(C1)\n",
    "    UP1 = Conv2D(128, (1, 1), activation=LeakyReLU(alpha=0.01), padding='same')(UP1)\n",
    "    L7 = UpSampling2D()(UP1)\n",
    "    C2 = concatenate([L7, CL3])\n",
    "    UP2 = Conv2D(64, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(C2)\n",
    "    UP2 = Conv2D(64, (1, 1), activation=LeakyReLU(alpha=0.01), padding='same')(UP2)\n",
    "    S1 = Conv2D(4, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(UP2)\n",
    "    S1 = UpSampling2D()(S1)\n",
    "    L8 = UpSampling2D()(UP2)\n",
    "    C3 = concatenate([L8, CL2])\n",
    "    UP3 = Conv2D(32, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(C3)\n",
    "    UP3 = Conv2D(32, (1, 1), activation=LeakyReLU(alpha=0.01), padding='same')(UP3)\n",
    "    S2 = Conv2D(4, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(UP3)\n",
    "    L9 = UpSampling2D()(UP3)\n",
    "    C4 = concatenate([L9, CL1])\n",
    "    L10 = Conv2D(32, (1, 1), activation=LeakyReLU(alpha=0.01), padding='same')(C4)\n",
    "\n",
    "    S3 = Conv2D(4, (3, 3), activation=LeakyReLU(alpha=0.01), padding='same')(L10)\n",
    "\n",
    "    #element wise summation of segmented layers\n",
    "    added_seg12 = Add()([S1, S2])\n",
    "    added_seg12 = UpSampling2D()(added_seg12)\n",
    "    added_seg123 = Add()([added_seg12, S3])\n",
    "    outputs = Conv2D(2, (1, 1), activation=\"sigmoid\")(added_seg123)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_plot(results):\n",
    "    \"\"\"This Function is used for used for plotting the graph of the training and Validation loss with respect to epoch\"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Binary_Crossentropy\")\n",
    "    plt.plot(results.history[\"loss\"], label=\"training_loss\")\n",
    "    plt.plot(results.history[\"val_loss\"], label=\"validation_loss\")\n",
    "    plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_plot(results):\n",
    "    \"\"\"This Function is used for Plotting the training and validation accuracy with respect to epochs\"\"\"\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.title(\"Classification Accuracy\")\n",
    "    plt.plot(results.history[\"accuracy\"],label=\"training_accuracy\")\n",
    "    plt.plot(results.history[\"val_accuracy\"],label=\"validation_accuracy\")\n",
    "    plt.plot(np.argmin(results.history[\"val_accuracy\"]),np.max(results.history[\"val_accuracy\"]),marker=\"x\",color=\"r\",label=\"best model\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(model,X_test,y_test):\n",
    "    \"\"\"This Function is used for Capturing the Best model for the epoch\"\"\"\n",
    "    model.load_weights('model-ISIC.h5')\n",
    "    test_preds=model.predict(X_test,verbose=1) # predict the model\n",
    "    test_preds_max=np.argmax(test_preds,axis=-1) # Returns the indices of the maximum values along an axis\n",
    "    n,h,w,g=y_test.shape\n",
    "    test_preds_reshape=test_preds_max.reshape(n,h,w,g)\n",
    "    return test_preds_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ISIc(X, y, Y_pred,ix=None):\n",
    "    \"\"\"This function is used for ploting the True image vs the Predictive image from the above model\"\"\"\n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "    else:\n",
    "        ix = ix\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix, ..., 0], cmap='gray')\n",
    "    ax[0].contour(X[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[0].set_title('Input Image')\n",
    "    \n",
    "    \n",
    "    ax[1].imshow(y[ix, ..., 0], cmap='gray')\n",
    "    ax[1].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[1].set_title('True Image')\n",
    "    \n",
    "    ax[2].imshow(Y_pred[ix, ..., 0], cmap='gray')\n",
    "    ax[2].contour(Y_pred[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[2].set_title('Predicted Image')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
