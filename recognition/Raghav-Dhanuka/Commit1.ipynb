{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the compression dimensions\n",
    "img_width = 256\n",
    "img_height =256\n",
    "border = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the file names of the images and masks in training, test and validation folders\n",
    "\n",
    "\n",
    "ids_train = next(os.walk(\"D:/ISIC2018_Task1-2_Training_Input_x2\"))[2] # returns all the files \"DIR.\"\n",
    "\n",
    "ids_seg_train=next(os.walk(\"D:/ISIC2018_Task1_Training_GroundTruth_x2\"))[2] # returns all the files \"DIR.\"\n",
    "\n",
    "print(\"No. of images in training folder= \",len(ids_train))\n",
    "print(\"No. of images in test folder= \",len(ids_seg_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train_sort=sorted(ids_train) # Sorting of data wit respect to labels\n",
    "ids_seg_train_sort=sorted(ids_seg_train) # Sorting of data wit respect to labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(inp_path,ids):\n",
    "    X= np.zeros((len(ids),img_height,img_width,1),dtype=np.float32)\n",
    "    for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)): # capture all the images ids using tqdm\n",
    "       \n",
    "        img = load_img(inp_path+id_, color_mode = 'grayscale')  # Load images here\n",
    "        x_img = img_to_array(img) # Convert images to array\n",
    "        x_img = resize(x_img,(256,256,1),mode = 'constant',preserve_range = True)\n",
    "        X[n] = x_img/255 # Normalize the images\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_seg(inp_path,ids):\n",
    "    X= np.zeros((len(ids),img_height,img_width,1),dtype=np.uint8)\n",
    "    for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n",
    "        # Load images\n",
    "        img = load_img(inp_path+id_,color_mode = 'grayscale')\n",
    "        x_img = img_to_array(img)\n",
    "        x_img = resize(x_img,(256,256,1),mode = 'constant', preserve_range = True)\n",
    "        X[n] = x_img\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Oasis_train = load_image(\"D:/ISIC2018_Task1-2_Training_Input_x2/\",ids_train_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Oasis_train=load_seg(\"D:/ISIC2018_Task1_Training_GroundTruth_x2/\",ids_seg_train_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_Oasis_train, Y_Oasis_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_Oasis_train_sc = y_train//85\n",
    "Y_Oasis_test_sc = y_test//85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_Oasis_train_cat = to_categorical(Y_Oasis_train_sc) # one hot encoding\n",
    "Y_Oasis_test_cat = to_categorical(Y_Oasis_test_sc) # one hot encoding\n",
    "Y_Oasis_val_cat = to_categorical(Y_Oasis_val_sc) # one hot encoding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
