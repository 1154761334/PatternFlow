{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import datasets, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, Concatenate, UpSampling2D, Conv2DTranspose, Dense\n",
    "from PIL import Image\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from datetime import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "data_dir = \"H:\\\\COMP3710\\\\data\"\n",
    "dst_case_train = data_dir + \"\\\\train\"\n",
    "dst_case_test = data_dir + \"\\\\test\"\n",
    "dst_case_validate = data_dir + \"\\\\validate\"\n",
    "dst_seg_train = data_dir + \"\\\\train_seg\"\n",
    "dst_seg_test = data_dir + \"\\\\test_seg\"\n",
    "dst_seg_validate = data_dir + \"\\\\validate_seg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.input_img_paths = input_img_paths\n",
    "        self.target_img_paths = target_img_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
    "        x = np.zeros((batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
    "        for j, path in enumerate(batch_input_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size)\n",
    "            x[j] = img\n",
    "        y = np.zeros((batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
    "        for j, path in enumerate(batch_target_img_paths):\n",
    "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
    "            y[j] = np.expand_dims(img, 2)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator_images = image_data_generator_train.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory='..//VOCdevkit/VOC2009/JPEGImages',\n",
    "    x_col='filename',\n",
    "    class_mode=None,\n",
    "    color_mode=\"rgb\",\n",
    "    target_size=(image_size[1],image_size[0]),\n",
    "    batch_size=batchSize,\n",
    "    seed=seed)\n",
    "\n",
    "train_generator_mask = mask_data_generator_train.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    directory='..//VOCdevkit/VOC2009/SegmentationClass',\n",
    "    x_col='segmentation',\n",
    "    class_mode=None,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(image_size[1],image_size[0]),\n",
    "    batch_size=batchSize,\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load functions\n",
    "\n",
    "def load_image(img_path):\n",
    "    return np.array(Image.open(fname)) / 255.\n",
    "\n",
    "def load_image_one_hot(img_path):\n",
    "    img =  np.array(Image.open(fname)) * (1./255.) # 0 to 1\n",
    "    img = np.ndarray.astype(img, np.uint8)\n",
    "    return (np.arange(img.max()+1) == img[...,None]).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load datasets\n",
    "\n",
    "data_dir = \"./\"\n",
    "folders = [\"ISIC2018_Task1-2_Training_Input_x2/\",\n",
    "          \"ISIC2018_Task1_Training_GroundTruth_x2/\"]\n",
    "case_pattern = \"ISIC_???????.jpg\"\n",
    "seg_pattern = \"ISIC_???????_segmentation.png\"\n",
    "\n",
    "# Pre-defined\n",
    "h, w = 1296, 1936\n",
    "seed = 123\n",
    "\n",
    "case_file_pattern = os.path.join(data_dir, folders[0], case_pattern)\n",
    "seg_file_pattern = os.path.join(data_dir, folders[1], seg_pattern)\n",
    "\n",
    "case_fname = glob.glob(case_file_pattern)\n",
    "seg_fname = glob.glob(seg_file_pattern)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cases:  2594\nsegs:  2594\n./ISIC2018_Task1-2_Training_Input_x2/ISIC_???????.jpg\n./ISIC2018_Task1_Training_GroundTruth_x2/ISIC_???????_segmentation.png\nD:\\s4354061\n"
     ]
    }
   ],
   "source": [
    "print(\"cases: \", len(case_fname))\n",
    "print(\"segs: \", len(seg_fname))\n",
    "print(case_file_pattern)\n",
    "print(seg_file_pattern)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ISIC2018_Task1-2_Training_Input_x2\\ISIC_0000000.jpg\n./ISIC2018_Task1_Training_GroundTruth_x2\\ISIC_0000000_segmentation.png\n"
     ]
    }
   ],
   "source": [
    "print(case_fname[0])\n",
    "print(seg_fname[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading case...\n"
     ]
    }
   ],
   "source": [
    "## DATA FORMATTING\n",
    "train_frac = 0.85\n",
    "case, seg = [], []\n",
    "\n",
    "print(\"Reading case...\")\n",
    "i=0\n",
    "for fname in (case_fname):\n",
    "    case.append(load_image(fname))\n",
    "    print(i)\n",
    "    i+=1\n",
    "\n",
    "# train_oh = load_image_one_hot(tf.constant(train_fname))\n",
    "    \n",
    "print(\"Reading seg...\")\n",
    "i = 0\n",
    "for fname in (seg_fname):\n",
    "    seg.append(load_image_one_hot(fname))\n",
    "    print(i)\n",
    "    i+=1\n",
    "\n",
    "train = np.array(train)\n",
    "seg = np.array(seg)\n",
    "\n",
    "case = case[:, :, :, np.newaxis]\n",
    "seg = seg[:, :, :, np.newaxis]\n",
    "\n",
    "\n",
    "\n",
    "print(\"Case images: \", case.shape, \"\\tdtype: \", case.dtype)\n",
    "print(\"Seg images: \", seg.shape, \"\\tdtype: \", seg.dtype)\n",
    "\n",
    "# del train_fname, test_fname, validate_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "case_shuffler = np. random. permutation(len(case))\n",
    "seg_shuffler = np. random. permutation(len(seg))\n",
    "\n",
    "case = case[case_shuffler]\n",
    "seg = seg[seg_shuffler]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
