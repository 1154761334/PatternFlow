{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "from matplotlib import image\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_input_path = './../dataset/ISIC2018_Task1-2_Training_Input_x2/*.jpg'\n",
    "isic_groundTruth_path = './../dataset/ISIC2018_Task1_Training_GroundTruth_x2/*.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_input = sorted(glob.glob(isic_input_path))\n",
    "isic_groundTruth = sorted(glob.glob(isic_groundTruth_path))\n",
    "\n",
    "DATASET_SIZE = len(isic_input)\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 192\n",
    "IMG_WIDTH = 256\n",
    "IMG_CHANNELS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * DATASET_SIZE)\n",
    "val_size = int(0.2 * DATASET_SIZE)\n",
    "test_size = int(0.1 * DATASET_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting up the dataset for training, validation, and testing\n",
    "\n",
    "full_ds = tf.data.Dataset.from_tensor_slices((isic_input, isic_groundTruth))\n",
    "full_ds = full_ds.shuffle(DATASET_SIZE, reshuffle_each_iteration=False)\n",
    "\n",
    "train_ds = full_ds.take(train_size)\n",
    "\n",
    "# skip the dataset for train\n",
    "test_ds = full_ds.skip(train_size)\n",
    "\n",
    "val_ds = full_ds.skip(val_size)\n",
    "test_ds = full_ds.take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    # resize the image 256*256 \n",
    "    image =  tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    # Standardise values to be in the [0, 1] range.\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    return image\n",
    "    \n",
    "def decode_label(label):\n",
    "    label = tf.image.decode_png(label, channels=1)\n",
    "    # Resize the image to the desired size.\n",
    "    label =  tf.image.resize(label, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    \n",
    "    label = tf.round(label / 255.0)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return label\n",
    "\n",
    "def decode_label_with_onehot(label):\n",
    "    label = tf.image.decode_png(label, channels=1)\n",
    "    # Resize the image to the desired size.\n",
    "    label =  tf.image.resize(label, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    \n",
    "    one_hot_map = []\n",
    "\n",
    "    for clr in [0, 255]:\n",
    "        class_map = tf.equal(label, clr)\n",
    "        class_map = tf.reduce_all(class_map,axis=-1)\n",
    "        one_hot_map.append(class_map)\n",
    "    \n",
    "    one_hot_map = tf.stack(one_hot_map, axis=-1)\n",
    "    one_hot_map = tf.cast(one_hot_map, tf.float32)\n",
    "    return one_hot_map\n",
    "\n",
    "    \n",
    "def process_data(image, label):\n",
    "    image = tf.io.read_file(image)\n",
    "    image = decode_img(image)\n",
    "    \n",
    "    label = tf.io.read_file(label)\n",
    "    label = decode_label(label)\n",
    "    # label = decode_label_with_onehot(label)\n",
    "    \n",
    "    return image, label   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Dataset.map to apply this transformation.\n",
    "processed_train_ds = train_ds.map(process_data)\n",
    "processed_val_ds = val_ds.map(process_data)\n",
    "processed_test_ds = test_ds.map(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "    print('Image shape:', image.numpy())\n",
    "    print('Label:', label.numpy())\n",
    "print()\n",
    "\n",
    "## Getting the input and output size\n",
    "input_size = (0, 0, 0)\n",
    "output_class_num = 0\n",
    "for image, label in processed_train_ds.take(1):\n",
    "    input_size = image.numpy().shape\n",
    "    output_class_num = label.numpy().shape[2]\n",
    "    print('Image shape:', image.numpy().shape)\n",
    "    print('Label:', label.numpy().shape)\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "print(output_class_num)\n",
    "\n",
    "# print(label)\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(image.numpy())\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "if (output_class_num > 1):\n",
    "    plt.imshow(tf.argmax(label.numpy(), axis=2))\n",
    "else:\n",
    "    plt.imshow(label.numpy())\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f*y_true_f) + K.sum(y_pred_f*y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def display(image, ground_truth, prediction, num):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    colors = ['black', 'green', 'red']\n",
    "    for i in range(num):\n",
    "        plt.subplot(4, 3, 3*i+1)\n",
    "        plt.imshow(image[i])\n",
    "        title = plt.title('The actual image')\n",
    "        plt.setp(title, color=colors[0])\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(4, 3, 3*i+2)\n",
    "        if (output_class_num > 1):\n",
    "            plt.imshow(tf.argmax(ground_truth[i], axis=2))\n",
    "        else:\n",
    "            plt.imshow(ground_truth[i])\n",
    "        title = plt.title('Ground truth image segmentation')\n",
    "        plt.setp(title, color=colors[1])\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(4, 3, 3*i+3)\n",
    "        if (output_class_num > 1):\n",
    "            plt.imshow(tf.argmax(prediction[i], axis=2))\n",
    "        else:\n",
    "            plt.imshow(prediction[i] > 0.5)\n",
    "        title = plt.title('Prediction image segmentation')\n",
    "        plt.setp(title, color=colors[2])\n",
    "        plt.axis('off')\n",
    "\n",
    "        print(\"DICE SIMILARITY FOR INPUT {}: {}\".format(i, dice_coef(ground_truth[i], prediction[i])))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def show_predictions(processed_test_ds, num=3):\n",
    "    image_test_batch, label_test_batch = next(iter(processed_test_ds.batch(num)))\n",
    "    prediction = model.predict(image_test_batch)\n",
    "    display(image_test_batch, label_test_batch, prediction, num)\n",
    "\n",
    "    \n",
    "from IPython.display import clear_output\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions(processed_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "\n",
    "## Use this one for the original unet model\n",
    "# model = unet(output_class_num, input_size)\n",
    "\n",
    "## Use this one for the improved unet model\n",
    "model = improved_unet(output_class_num, input_size)\n",
    "\n",
    "print(\"Loss Function: dice similarity coefficient\")\n",
    "model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy', dice_coef])\n",
    "\n",
    "print()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(processed_train_ds.batch(BATCH_SIZE), \n",
    "                    validation_data=processed_val_ds.batch(BATCH_SIZE), \n",
    "                    epochs=10, callbacks=[DisplayCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(processed_test_ds.batch(BATCH_SIZE), verbose=1)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test_batch, label_test_batch = next(iter(processed_test_ds.batch(test_size)))\n",
    "predictions = model.predict(image_test_batch)\n",
    "\n",
    "print(predictions.shape)\n",
    "# plt.imshow(predictions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_dsc = 0\n",
    "total_dsc = 0\n",
    "length = predictions.shape[0]\n",
    "min_dsc = 0.8\n",
    "print(\"DSC BELOW {}:\".format(min_dsc))\n",
    "for i in range(length):\n",
    "    dsc = dice_coef(label_test_batch[i], predictions[i])\n",
    "    if dsc < min_dsc:\n",
    "        bad_dsc += 1\n",
    "        print(\"  Index {}, dsc is {}\".format(i, dsc))\n",
    "    total_dsc += dsc\n",
    "\n",
    "print()\n",
    "print(\"There are {} bad dsc (< 0.8) out of {}\".format(bad_dsc, length))\n",
    "print(\"There are {} good dsc (>= 0.8) out of {}\".format((length-bad_dsc), length))\n",
    "print(\"Average dsc: \", total_dsc/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(predictions[1] > 0.5)\n",
    "plt.imshow(image_test_batch[100])\n",
    "# plt.imshow(tf.argmax(label_test_batch[100], axis=2))\n",
    "# plt.imshow(predictions[100][:,:,1] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = test_ds.as_numpy_iterator()\n",
    "#     print('Image shape:', image.numpy())\n",
    "#     print('Label:', label.numpy())\n",
    "print(list(ds)[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
