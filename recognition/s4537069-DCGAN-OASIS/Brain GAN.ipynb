{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Set to TF to GPU\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up directories for dataset (These were retrived from D: in the GPU lab)\n",
    "\n",
    "# Test\n",
    "test_directory = sorted(glob.glob(\"D:\\keras_png_slices_data\\keras_png_slices_test\\*.png\"))\n",
    "seg_test_directory = sorted(glob.glob(\"D:\\keras_png_slices_data\\keras_png_slices_seg_test\\*.png\"))\n",
    "\n",
    "# Train\n",
    "train_directory = sorted(glob.glob(\"D:\\keras_png_slices_data\\keras_png_slices_train\\*.png\"))\n",
    "seg_train_directory = sorted(glob.glob(\"D:\\keras_png_slices_data\\keras_png_slices_seg_train\\*.png\"))\n",
    "\n",
    "# Validation\n",
    "validation_directory = sorted(glob.glob(\"D:\\keras_png_slices_data\\keras_png_slices_validate\\*.png\"))\n",
    "seg_validation_directory = sorted(glob.glob(\"D:\\keras_png_slices_data\\keras_png_slices_seg_validate\\*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates datasets, slice tensors, shuffle them.\n",
    "\n",
    "# Test\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test_directory)\n",
    "test_data = test_data.shuffle(len(test_directory))\n",
    "\n",
    "# Train\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train_directory)\n",
    "train_data = test_data.shuffle(len(train_directory))\n",
    "\n",
    "# Validation\n",
    "validation_data = tf.data.Dataset.from_tensor_slices(validation_directory)\n",
    "validation_data = test_data.shuffle(len(validation_directory))                                               \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map function\n",
    "\n",
    "def pre_processing(input):\n",
    "    \n",
    "    # Read/output contents of filename\n",
    "    data = tf.io.read_file(input)\n",
    "    \n",
    "    # Convert images to grayscale\n",
    "    data = tf.image.decode_png(data, channels = 1)\n",
    "    \n",
    "    # Resize to 256*256\n",
    "    data = tf.image.resize(data, (256,256))\n",
    "    \n",
    "    # Normalise to (-1,1)\n",
    "    data = tf.cast(data, tf.float32)\n",
    "    data = (data - 127.5)/127.5\n",
    "\n",
    "    return data\n",
    "\n",
    "# Function to map datasets and set batch sizes\n",
    "\n",
    "def map_and_batch(input, map_func, batch_size):\n",
    "    \n",
    "    input = input.map(map_func).batch(batch_size)\n",
    "    \n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply pre-prcoessing functions to the data\n",
    "\n",
    "test_data = map_and_batch(test_data, pre_processing, 16)\n",
    "train_data = map_and_batch(train_data, pre_processing, 16)\n",
    "validation_data = map_and_batch(validation_data, pre_processing, 16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
