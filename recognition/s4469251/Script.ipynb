{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import Input, LeakyReLU, Conv2D as conv2D, Dropout, Add, UpSampling2D, concatenate\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "from matplotlib import colors, cm\n",
    "from ImprovedUnet import improved_unet\n",
    "\n",
    "\n",
    "HEIGHT = 256\n",
    "WIDTH = 256\n",
    "TRAIN_SIZE = 1815\n",
    "TEST_SIZE = 389\n",
    "VALI_SIZE = 389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given prediction images and ground truth imgaes. Return the dice similarity coefficient\n",
    "def dice_coef(predictions, truth, axis=(1,2,3)):\n",
    "    predictions = tf.convert_to_tensor(predictions, np.float32)\n",
    "    truth = tf.convert_to_tensor(truth, np.float32)\n",
    "    numerator = (2.0 * (tf.reduce_sum(predictions * truth, axis=axis))) + 1\n",
    "    denominator = tf.reduce_sum(predictions, axis=axis) + tf.reduce_sum(truth, axis=axis) + 1\n",
    "    coef = tf.reduce_mean(numerator / denominator)\n",
    "    return coef\n",
    "\n",
    "# Return the dice similarity coefficient loss\n",
    "def dice_coef_loss(predictions, truth):\n",
    "    return 1 - dice_coef(predictions, truth)\n",
    "\n",
    "# Read images from row image file name and ground truth file name\n",
    "def read_images(image_file, mask_file):\n",
    "    img = cv2.imread(image_file)\n",
    "    img = cv2.resize(img, (HEIGHT, WIDTH))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img/255\n",
    "    img = (img - img.mean())/img.std()\n",
    "    mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (HEIGHT, WIDTH))\n",
    "    mask = np.round(mask/255)\n",
    "    mask = mask[:, :, np.newaxis]\n",
    "    return img, mask\n",
    "\n",
    "# Image gererator loaded batchsize number of random pairs of row images and ground truth images.\n",
    "def image_generator(image_fnames, mask_fnames, batchsize):\n",
    "    count = len(image_fnames)\n",
    "    while True:\n",
    "        random_indices = random.sample(range(count), batchsize)\n",
    "        batch_img, batch_mask = [], []\n",
    "        for index in random_indices:\n",
    "            img, mask = read_images(image_fnames[index], mask_fnames[index])\n",
    "            batch_img.append(img)\n",
    "            batch_mask.append(mask)\n",
    "        images = np.stack(batch_img, axis=0)\n",
    "        masks = np.stack(batch_mask, axis=0)\n",
    "        yield images, masks \n",
    "\n",
    "# Plot five pair of row images and ground truth images from data generator.\n",
    "def plot_gen(data_gen):\n",
    "    images, masks = next(data_gen)\n",
    "    plot_images(images, 3)\n",
    "    plot_images(masks, 1)\n",
    "\n",
    "# Plot five images in one row. Set dim=1 when plotting gray images, set dim to 3 when plotting color images.\n",
    "def plot_images(images, dim):\n",
    "    fig, axs = plt.subplots(1, 5, sharey=True, figsize=(15,15))\n",
    "    for i in range(5):\n",
    "        if dim == 3:\n",
    "            img = images[i, :, :, :]\n",
    "            norm = colors.LogNorm(img.mean() + 0.5 * img.std(), img.max(), clip='True')  \n",
    "            axs[i].imshow(img, cmap=cm.gray, norm=norm, origin=\"lower\")\n",
    "            axs[i].axis('off')\n",
    "        elif dim == 1:\n",
    "            img = images[i, :, :, 0]\n",
    "            axs[i].imshow(img, cmap='gray')\n",
    "            axs[i].axis('off')            \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot five pairs of row images, ground truth images and their corresponding predictions.\n",
    "def plot_comparison(images, test_masks, predictions):\n",
    "    images, test_masks, predictions = generate_random_images(images, test_masks, predictions)\n",
    "    plot_images(images, 3)\n",
    "    plot_images(test_masks, 1)    \n",
    "    plot_images(predictions, 1)\n",
    "\n",
    "# Generate five random images for row images, ground truth images and their corresponding predictions.\n",
    "def generate_random_images(test_images, test_masks, predictions):\n",
    "    random_indices = random.sample(range(TEST_SIZE), 5)\n",
    "    imgs = []\n",
    "    preds = []\n",
    "    masks = []\n",
    "    for i in random_indices:\n",
    "        imgs.append(test_images[i, :, :, :])\n",
    "        masks.append(test_masks[i, :, :, :])\n",
    "        preds.append(predictions[i, :, :, :])\n",
    "    imgs = np.stack(imgs, axis=0)\n",
    "    masks = np.stack(masks, axis=0)\n",
    "    preds = np.stack(preds, axis=0)\n",
    "    return imgs, masks, preds\n",
    "\n",
    "# Load images from raw images and ground truth file names, return them as numpy arrays\n",
    "def load_images_from_fn(image_fnames, mask_fnames):\n",
    "    images = []\n",
    "    masks = []\n",
    "    for i in range(len(image_fnames)):\n",
    "        img, mask = read_images(image_fnames[i], mask_fnames[i])\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "    images = np.stack(images, axis=0)\n",
    "    masks = np.stack(masks, axis=0)\n",
    "    return images, masks\n",
    "\n",
    "# Load raw images using PIL\n",
    "def load_original_test_images(test_x):\n",
    "    images = []\n",
    "    for file in test_x:\n",
    "        img = PIL.Image.open(str(file))\n",
    "        img = ImageOps.flip(img)\n",
    "        img = img.resize((HEIGHT, WIDTH))\n",
    "        img = np.array(img.getdata()).reshape(HEIGHT, WIDTH, 3)\n",
    "        images.append(img)\n",
    "    images = np.stack(images, axis=0)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images, return training, validation generator, return test_masks, test_images in numpy format.\n",
    "# return test_images_forplot because the test_images loaded are normalized. \n",
    "def load_data():\n",
    "    input_images = sorted(glob.glob(\"H:\\\\COMP3710/report/ISIC2018_Task1-2_Training_Data/input/*.jpg\"))\n",
    "    output_masks = sorted(glob.glob(\"H:\\\\COMP3710/report/ISIC2018_Task1-2_Training_Data/truth/*.png\"))\n",
    "    \n",
    "    # Separate file names to train, validation and test.\n",
    "    DATASET_SIZE = len(input_images)\n",
    "    train_size = int(DATASET_SIZE * 0.7)\n",
    "    val_size = test_size = int(DATASET_SIZE * 0.15)\n",
    "    train_x = input_images[0:train_size]\n",
    "    train_y = output_masks[0:train_size]\n",
    "    test_x = input_images[train_size:train_size+test_size]\n",
    "    test_y = output_masks[train_size:train_size+test_size]\n",
    "    val_x = input_images[train_size+test_size:]\n",
    "    val_y = output_masks[train_size+test_size:]\n",
    "    \n",
    "    train_gen = image_generator(train_x, train_y, 10)\n",
    "    val_gen = image_generator(val_x, val_y, 10)\n",
    "    test_images, test_masks = load_images_from_fn(test_x, test_y)\n",
    "    test_images_forplot = load_original_test_images(test_x)\n",
    "    print('Loading success')\n",
    "    return train_gen, val_gen, test_masks, test_images, test_images_forplot\n",
    "\n",
    "# Compile and fit model, return model and history.\n",
    "def compile_model(train_gen, val_gen):\n",
    "    model = improved_unet(HEIGHT, WIDTH)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[dice_coef, 'acc'])\n",
    "    # Create check point\n",
    "    checkpoint_filepath = '/tmp/checkpoint'\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='acc',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "    # Compile model\n",
    "    train_history = model.fit(train_gen, epochs=250, steps_per_epoch=10, validation_data = val_gen, validation_steps=10)\n",
    "    return model, train_history\n",
    "\n",
    "# Training loss, accuracy, and dsc are plotted.\n",
    "def plot_training_results(train_history):\n",
    "    plt.plot(train_history.history['loss'], 'k', label='Training loss')\n",
    "    plt.plot(train_history.history['val_loss'], 'b', label = 'Validation loss')\n",
    "    plt.title('Loss of trained data')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_history.history['acc'], 'k', label='Training accuracy')\n",
    "    plt.plot(train_history.history['val_acc'], 'b', label='Validation accuracy')\n",
    "    plt.title('Accuracy of trained data')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_history.history['dice_coef'], 'k', label='Training dsc ')\n",
    "    plt.plot(train_history.history['val_dice_coef'], 'b', label='Validation dsc')\n",
    "    plt.title('Dice similarity coefficient of trained data')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Dice similarity coefficient')\n",
    "    plt.legend()\n",
    "    plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading success\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 10 steps, validate for 10 steps\n",
      "Epoch 1/250\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.6989 - dice_coef: 0.2438 - acc: 0.6562 - val_loss: 0.6897 - val_dice_coef: 0.2682 - val_acc: 0.7574\n",
      "Epoch 2/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.6885 - dice_coef: 0.2534 - acc: 0.7846 - val_loss: 0.6882 - val_dice_coef: 0.3041 - val_acc: 0.7238\n",
      "Epoch 3/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.6823 - dice_coef: 0.2382 - acc: 0.8018 - val_loss: 0.6776 - val_dice_coef: 0.2955 - val_acc: 0.7269\n",
      "Epoch 4/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6153 - dice_coef: 0.2091 - acc: 0.7799 - val_loss: 0.5783 - val_dice_coef: 0.2335 - val_acc: 0.7308\n",
      "Epoch 5/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5291 - dice_coef: 0.1538 - acc: 0.8165 - val_loss: 0.5528 - val_dice_coef: 0.2584 - val_acc: 0.7248\n",
      "Epoch 6/250\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.5026 - dice_coef: 0.1776 - acc: 0.8013 - val_loss: 0.5045 - val_dice_coef: 0.2454 - val_acc: 0.7787\n",
      "Epoch 7/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.5206 - dice_coef: 0.2165 - acc: 0.7734 - val_loss: 0.5183 - val_dice_coef: 0.2930 - val_acc: 0.7351\n",
      "Epoch 8/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.4493 - dice_coef: 0.2324 - acc: 0.8029 - val_loss: 0.4926 - val_dice_coef: 0.3048 - val_acc: 0.7350\n",
      "Epoch 9/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.5155 - dice_coef: 0.2519 - acc: 0.7634 - val_loss: 0.4815 - val_dice_coef: 0.3198 - val_acc: 0.7428\n",
      "Epoch 10/250\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.3856 - dice_coef: 0.2491 - acc: 0.8338 - val_loss: 0.4484 - val_dice_coef: 0.3411 - val_acc: 0.7411\n",
      "Epoch 11/250\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.4494 - dice_coef: 0.2866 - acc: 0.7891 - val_loss: 0.4465 - val_dice_coef: 0.3249 - val_acc: 0.8428\n",
      "Epoch 12/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3888 - dice_coef: 0.3131 - acc: 0.8519 - val_loss: 0.3414 - val_dice_coef: 0.5451 - val_acc: 0.8637\n",
      "Epoch 13/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4071 - dice_coef: 0.4379 - acc: 0.8459 - val_loss: 0.4149 - val_dice_coef: 0.4885 - val_acc: 0.8633\n",
      "Epoch 14/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4211 - dice_coef: 0.3905 - acc: 0.8477 - val_loss: 0.3843 - val_dice_coef: 0.4914 - val_acc: 0.8752\n",
      "Epoch 15/250\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.3613 - dice_coef: 0.4534 - acc: 0.8802 - val_loss: 0.3287 - val_dice_coef: 0.5076 - val_acc: 0.8703\n",
      "Epoch 16/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3604 - dice_coef: 0.4683 - acc: 0.8791 - val_loss: 0.3762 - val_dice_coef: 0.4317 - val_acc: 0.8792\n",
      "Epoch 17/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3560 - dice_coef: 0.4648 - acc: 0.8775 - val_loss: 0.3911 - val_dice_coef: 0.5304 - val_acc: 0.8708\n",
      "Epoch 18/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4112 - dice_coef: 0.3923 - acc: 0.8594 - val_loss: 0.3556 - val_dice_coef: 0.4728 - val_acc: 0.9024\n",
      "Epoch 19/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3593 - dice_coef: 0.4740 - acc: 0.8739 - val_loss: 0.3142 - val_dice_coef: 0.5717 - val_acc: 0.9012\n",
      "Epoch 20/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3242 - dice_coef: 0.4913 - acc: 0.8990 - val_loss: 0.2880 - val_dice_coef: 0.5430 - val_acc: 0.9050\n",
      "Epoch 21/250\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.3168 - dice_coef: 0.4959 - acc: 0.8979 - val_loss: 0.3397 - val_dice_coef: 0.5233 - val_acc: 0.8945\n",
      "Epoch 22/250\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.3487 - dice_coef: 0.4793 - acc: 0.8860 - val_loss: 0.3259 - val_dice_coef: 0.5939 - val_acc: 0.8954\n",
      "Epoch 23/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2604 - dice_coef: 0.4417 - acc: 0.9235 - val_loss: 0.2819 - val_dice_coef: 0.6058 - val_acc: 0.9072\n",
      "Epoch 24/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3506 - dice_coef: 0.4729 - acc: 0.8989 - val_loss: 0.3557 - val_dice_coef: 0.5359 - val_acc: 0.8772\n",
      "Epoch 25/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3468 - dice_coef: 0.4560 - acc: 0.8830 - val_loss: 0.3167 - val_dice_coef: 0.5804 - val_acc: 0.8884\n",
      "Epoch 26/250\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2622 - dice_coef: 0.5353 - acc: 0.9156 - val_loss: 0.3316 - val_dice_coef: 0.5440 - val_acc: 0.8889\n",
      "Epoch 27/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2652 - dice_coef: 0.5451 - acc: 0.9188 - val_loss: 0.2910 - val_dice_coef: 0.5434 - val_acc: 0.9013\n",
      "Epoch 28/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2938 - dice_coef: 0.4763 - acc: 0.9062 - val_loss: 0.3279 - val_dice_coef: 0.4901 - val_acc: 0.8941\n",
      "Epoch 29/250\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.3111 - dice_coef: 0.5626 - acc: 0.8923 - val_loss: 0.2693 - val_dice_coef: 0.5670 - val_acc: 0.9226\n",
      "Epoch 30/250\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.3180 - dice_coef: 0.5049 - acc: 0.9011 - val_loss: 0.3423 - val_dice_coef: 0.5478 - val_acc: 0.8922\n",
      "Epoch 31/250\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2890 - dice_coef: 0.5598 - acc: 0.9098 - val_loss: 0.2988 - val_dice_coef: 0.6130 - val_acc: 0.8955\n",
      "Epoch 32/250\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.3124 - dice_coef: 0.5171 - acc: 0.9106 - val_loss: 0.3236 - val_dice_coef: 0.5125 - val_acc: 0.9122\n",
      "Epoch 33/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.1920 - dice_coef: 0.5546 - acc: 0.9343 - val_loss: 0.2489 - val_dice_coef: 0.6944 - val_acc: 0.9265\n",
      "Epoch 34/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3060 - dice_coef: 0.5698 - acc: 0.9076 - val_loss: 0.2545 - val_dice_coef: 0.5903 - val_acc: 0.9169\n",
      "Epoch 35/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3129 - dice_coef: 0.4909 - acc: 0.8938 - val_loss: 0.3437 - val_dice_coef: 0.5450 - val_acc: 0.8868\n",
      "Epoch 36/250\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.2905 - dice_coef: 0.5303 - acc: 0.9030 - val_loss: 0.3138 - val_dice_coef: 0.5780 - val_acc: 0.8832\n",
      "Epoch 37/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2009 - dice_coef: 0.5545 - acc: 0.9267 - val_loss: 0.2458 - val_dice_coef: 0.6449 - val_acc: 0.9150\n",
      "Epoch 38/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2479 - dice_coef: 0.6158 - acc: 0.9190 - val_loss: 0.2745 - val_dice_coef: 0.6187 - val_acc: 0.9060\n",
      "Epoch 39/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.1956 - dice_coef: 0.5459 - acc: 0.9308 - val_loss: 0.3057 - val_dice_coef: 0.6683 - val_acc: 0.8875\n",
      "Epoch 40/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2260 - dice_coef: 0.6031 - acc: 0.9203 - val_loss: 0.2660 - val_dice_coef: 0.6151 - val_acc: 0.9050\n",
      "Epoch 41/250\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.2511 - dice_coef: 0.6020 - acc: 0.9080 - val_loss: 0.2579 - val_dice_coef: 0.5636 - val_acc: 0.9229\n",
      "Epoch 42/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2082 - dice_coef: 0.6092 - acc: 0.9258 - val_loss: 0.2798 - val_dice_coef: 0.6116 - val_acc: 0.9009\n",
      "Epoch 43/250\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.2409 - dice_coef: 0.5736 - acc: 0.9183 - val_loss: 0.2652 - val_dice_coef: 0.5811 - val_acc: 0.9220\n",
      "Epoch 44/250\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.2872 - dice_coef: 0.5360 - acc: 0.9005 - val_loss: 0.2905 - val_dice_coef: 0.5711 - val_acc: 0.9036\n",
      "Epoch 45/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2360 - dice_coef: 0.5894 - acc: 0.9126 - val_loss: 0.2467 - val_dice_coef: 0.6284 - val_acc: 0.9231\n",
      "Epoch 46/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 13s 1s/step - loss: 0.2301 - dice_coef: 0.5901 - acc: 0.9137 - val_loss: 0.3301 - val_dice_coef: 0.6118 - val_acc: 0.8798\n",
      "Epoch 47/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2817 - dice_coef: 0.5146 - acc: 0.9065 - val_loss: 0.2534 - val_dice_coef: 0.6126 - val_acc: 0.9241\n",
      "Epoch 48/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2248 - dice_coef: 0.6302 - acc: 0.9148 - val_loss: 0.3338 - val_dice_coef: 0.5791 - val_acc: 0.8982\n",
      "Epoch 49/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2599 - dice_coef: 0.6127 - acc: 0.9055 - val_loss: 0.2662 - val_dice_coef: 0.6074 - val_acc: 0.9111\n",
      "Epoch 50/250\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.2780 - dice_coef: 0.5294 - acc: 0.9017 - val_loss: 0.3018 - val_dice_coef: 0.5545 - val_acc: 0.9016\n",
      "Epoch 51/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2259 - dice_coef: 0.5879 - acc: 0.9189 - val_loss: 0.2701 - val_dice_coef: 0.6394 - val_acc: 0.9086\n",
      "Epoch 52/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1632 - dice_coef: 0.6544 - acc: 0.9385 - val_loss: 0.2531 - val_dice_coef: 0.6445 - val_acc: 0.9086\n",
      "Epoch 53/250\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2704 - dice_coef: 0.5710 - acc: 0.9086 - val_loss: 0.3050 - val_dice_coef: 0.5550 - val_acc: 0.9127\n",
      "Epoch 54/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2494 - dice_coef: 0.5346 - acc: 0.9035 - val_loss: 0.2685 - val_dice_coef: 0.6499 - val_acc: 0.9031\n",
      "Epoch 55/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2322 - dice_coef: 0.5785 - acc: 0.9151 - val_loss: 0.2550 - val_dice_coef: 0.6525 - val_acc: 0.9027\n",
      "Epoch 56/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2333 - dice_coef: 0.5694 - acc: 0.9207 - val_loss: 0.2391 - val_dice_coef: 0.5917 - val_acc: 0.9182\n",
      "Epoch 57/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2229 - dice_coef: 0.6183 - acc: 0.9158 - val_loss: 0.2928 - val_dice_coef: 0.6170 - val_acc: 0.8944\n",
      "Epoch 58/250\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.1668 - dice_coef: 0.6335 - acc: 0.9386 - val_loss: 0.1941 - val_dice_coef: 0.6737 - val_acc: 0.9288\n",
      "Epoch 59/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.1950 - dice_coef: 0.6380 - acc: 0.9293 - val_loss: 0.3426 - val_dice_coef: 0.5852 - val_acc: 0.8886\n",
      "Epoch 60/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2671 - dice_coef: 0.5862 - acc: 0.8956 - val_loss: 0.2796 - val_dice_coef: 0.5937 - val_acc: 0.9114\n",
      "Epoch 61/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2226 - dice_coef: 0.6196 - acc: 0.9127 - val_loss: 0.2349 - val_dice_coef: 0.6541 - val_acc: 0.9188\n",
      "Epoch 62/250\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.2021 - dice_coef: 0.6241 - acc: 0.9229 - val_loss: 0.2684 - val_dice_coef: 0.6214 - val_acc: 0.9024\n",
      "Epoch 63/250\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.2103 - dice_coef: 0.6467 - acc: 0.9213 - val_loss: 0.2498 - val_dice_coef: 0.6623 - val_acc: 0.9060\n",
      "Epoch 64/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2094 - dice_coef: 0.6013 - acc: 0.9197 - val_loss: 0.2227 - val_dice_coef: 0.6704 - val_acc: 0.9176\n",
      "Epoch 65/250\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.2093 - dice_coef: 0.6419 - acc: 0.9221 - val_loss: 0.2885 - val_dice_coef: 0.6674 - val_acc: 0.8978\n",
      "Epoch 66/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1970 - dice_coef: 0.6114 - acc: 0.9232 - val_loss: 0.2437 - val_dice_coef: 0.6298 - val_acc: 0.9124\n",
      "Epoch 67/250\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.1696 - dice_coef: 0.6240 - acc: 0.9349 - val_loss: 0.2834 - val_dice_coef: 0.6554 - val_acc: 0.8987\n",
      "Epoch 68/250\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.1807 - dice_coef: 0.6216 - acc: 0.9341 - val_loss: 0.2325 - val_dice_coef: 0.6438 - val_acc: 0.9047\n",
      "Epoch 69/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2184 - dice_coef: 0.5892 - acc: 0.9210 - val_loss: 0.2741 - val_dice_coef: 0.6065 - val_acc: 0.8964\n",
      "Epoch 70/250\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.1890 - dice_coef: 0.6235 - acc: 0.9295 - val_loss: 0.3726 - val_dice_coef: 0.6298 - val_acc: 0.8882\n",
      "Epoch 71/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2133 - dice_coef: 0.6185 - acc: 0.9252 - val_loss: 0.2273 - val_dice_coef: 0.6064 - val_acc: 0.9221\n",
      "Epoch 72/250\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2404 - dice_coef: 0.6347 - acc: 0.9052 - val_loss: 0.2563 - val_dice_coef: 0.5900 - val_acc: 0.9077\n",
      "Epoch 73/250\n",
      "10/10 [==============================] - 12s 1s/step - loss: 0.2253 - dice_coef: 0.6046 - acc: 0.9169 - val_loss: 0.2168 - val_dice_coef: 0.6373 - val_acc: 0.9239\n",
      "Epoch 74/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1783 - dice_coef: 0.6444 - acc: 0.9306 - val_loss: 0.3034 - val_dice_coef: 0.6610 - val_acc: 0.9074\n",
      "Epoch 75/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2521 - dice_coef: 0.5716 - acc: 0.9061 - val_loss: 0.2591 - val_dice_coef: 0.6080 - val_acc: 0.9149\n",
      "Epoch 76/250\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2159 - dice_coef: 0.5930 - acc: 0.9196 - val_loss: 0.2371 - val_dice_coef: 0.7145 - val_acc: 0.9129\n",
      "Epoch 77/250\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.1944 - dice_coef: 0.6823 - acc: 0.9326 - val_loss: 0.1751 - val_dice_coef: 0.7134 - val_acc: 0.9394\n",
      "Epoch 78/250\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 0.1937 - dice_coef: 0.6304 - acc: 0.9230"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load training ang validation data generator, load test images and masks as numpy array. \n",
    "    # Raw test images with no preprocess is also loaded for plotting\n",
    "    train_gen, val_gen, test_masks, test_images, test_images_forplot = load_data()\n",
    "    # Model is compiled with given train and validation data generator.\n",
    "    model, train_history = compile_model(train_gen, val_gen)\n",
    "    # Training loss, accuracy, dsc are plotted.\n",
    "    plot_training_results(train_history)\n",
    "    # Predicted images are loaded\n",
    "    predictions = np.round(model.predict(test_images))\n",
    "    # Prediced images are compaired with raw image and true masks\n",
    "    plot_comparison(test_images_forplot, test_masks, predictions)\n",
    "    # Dice coefficient of the prediction is calculated.\n",
    "    dsc = dice_coef(predictions, test_masks)\n",
    "    dsc = dsc.numpy()\n",
    "    print('Dice similarity coefficient: ' + str(dsc))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
