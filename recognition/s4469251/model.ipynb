{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "HEIGHT = 256\n",
    "WIDTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_jpg(file_path):\n",
    "    jpg = tf.io.read_file(file_path)\n",
    "    jpg = tf.io.decode_jpeg(jpg, channels=3)\n",
    "    return jpg\n",
    "\n",
    "def decode_png(file_path):\n",
    "    png = tf.io.read_file(file_path)\n",
    "    png = tf.io.decode_png(png, channels=1)\n",
    "    return png\n",
    "\n",
    "def process_path(image_fp, mask_fp):\n",
    "    image = decode_jpg(image_fp)\n",
    "    mask = decode_png(mask_fp)\n",
    "    return image, mask\n",
    "    \n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.imshow(display_list[i], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def resize_images(image, mask):\n",
    "    image = tf.image.resize(image, [HEIGHT, WIDTH])\n",
    "    image = image[np.newaxis, :, :,:]\n",
    "    image = image/255\n",
    "    image = (image - image.mean())/image.std()\n",
    "    mask = tf.image.resize(mask, [HEIGHT, WIDTH])\n",
    "    mask = mask[np.newaxis, :, :,:]\n",
    "    mask = tf.math.round(mask/255)\n",
    "    return image, mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import Input, LeakyReLU, Conv2D as conv2D, Dropout, Add, UpSampling2D, concatenate\n",
    "\n",
    "\n",
    "def improved_unet(W, H):\n",
    "    input_size = (W, H, 3)\n",
    "    inputs = Input(input_size)\n",
    "    print(inputs)\n",
    "    #W*H*16\n",
    "    conv1 = conv2D(16, 3, activation = tf.keras.layers.LeakyReLU(alpha=0.01), padding = 'same')(inputs)\n",
    "    cont1 = conv2D(16, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(conv1)\n",
    "    cont1 = Dropout(0.3)(cont1)\n",
    "    cont1 = conv2D(16, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(cont1)\n",
    "    conc1 = Add()([conv1, cont1]) #W*H*16\n",
    "    # W/2 * H/2 * 32\n",
    "  \n",
    "    conv2 = conv2D(32, 3, strides = (2,2), activation = LeakyReLU(alpha=0.01), padding = 'same')(conc1)\n",
    "    cont2 = conv2D(32, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(conv2)\n",
    "    cont2 = Dropout(0.3)(cont2)\n",
    "    cont2 = conv2D(32, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(cont2)\n",
    "    conc2 = Add()([conv2, cont2]) #W/2*H/2*32\n",
    "\n",
    "    conv3 = conv2D(64, 3, strides = (2,2), activation = LeakyReLU(alpha=0.01), padding = 'same')(conc2)\n",
    "    cont3 = conv2D(64, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(conv3)\n",
    "    cont3 = Dropout(0.3)(cont3)\n",
    "    cont3 = conv2D(64, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(cont3)\n",
    "    conc3 = Add()([conv3, cont3]) #W/4*H/4*64\n",
    "\n",
    "    conv4 = conv2D(128, 3, strides = (2,2), activation = LeakyReLU(alpha=0.01), padding = 'same')(conc3)\n",
    "    cont4 = conv2D(128, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(conv4)\n",
    "    cont4 = Dropout(0.3)(cont4)\n",
    "    cont4 = conv2D(128, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(cont4)\n",
    "    conc4 = Add()([conv4, cont4]) #W/8*H/8*128\n",
    " \n",
    "    conv5 = conv2D(256, 3, strides = (2,2), activation = LeakyReLU(alpha=0.01), padding = 'same')(conc4)\n",
    "    cont5 = conv2D(256, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(conv5)\n",
    "    cont5 = Dropout(0.3)(cont5)\n",
    "    cont5 = conv2D(256, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(cont5)\n",
    "    conc5 = Add()([conv5, cont5]) #W/16*H/16*256\n",
    "\n",
    "    uconv5 = UpSampling2D(size = (2,2))(conc5)\n",
    "    uconv5 = conv2D(128, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(uconv5)\n",
    " \n",
    "    uconv4 = concatenate([uconv5, conc4])\n",
    "    lconv4 = conv2D(128, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(uconv4)\n",
    "    lconv4 = conv2D(128, 1, activation = LeakyReLU(alpha=0.01), padding = 'same')(lconv4)\n",
    "    uconv4 = UpSampling2D(size = (2,2))(uconv4)\n",
    "    uconv4 = conv2D(64, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(uconv4)\n",
    " \n",
    "    uconv3 = concatenate([uconv4, conc3])\n",
    "    lconv3 = conv2D(64, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(uconv3)\n",
    "    lconv3 = conv2D(64, 1, activation = LeakyReLU(alpha=0.01), padding = 'same')(lconv3)\n",
    "    sconv3 = conv2D(1, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(lconv3) \n",
    "    sconv3 = UpSampling2D(size = (2,2))(sconv3) \n",
    "    uconv3 = UpSampling2D(size = (2,2))(lconv3)\n",
    "    uconv3 = conv2D(32, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(uconv3)\n",
    "\n",
    "    uconv2 = concatenate([uconv3, conc2])   \n",
    "    lconv2 = conv2D(32, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(uconv2)\n",
    "    lconv2 = conv2D(32, 1, activation = LeakyReLU(alpha=0.01), padding = 'same')(lconv2)\n",
    "    sconv2 = conv2D(1, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(lconv2) \n",
    "    sconv2 = Add()([sconv2, sconv3])\n",
    "    sconv2 = UpSampling2D(size = (2,2))(lconv2)\n",
    "    uconv2 = UpSampling2D(size = (2,2))(uconv2)\n",
    "    uconv2 = conv2D(16, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(uconv2)\n",
    "    \n",
    "    uconv1 = concatenate([uconv2, conc1])\n",
    "    uconv1 = conv2D(32, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(uconv1)\n",
    "    sconv1 = conv2D(1, 3, activation = LeakyReLU(alpha=0.01), padding = 'same')(uconv1) \n",
    "    sconv1 = Add()([sconv1, sconv2])\n",
    "    output = conv2D(1, 1, activation = 'sigmoid')(sconv1)\n",
    "    model = Model(inputs = inputs, outputs = output)\n",
    "    return model\n",
    "\n",
    "                          \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_images = sorted(glob.glob(\"H:\\\\COMP3710/report/ISIC2018_Task1-2_Training_Data/input/*.jpg\"))\n",
    "output_masks = sorted(glob.glob(\"H:\\\\COMP3710/report/ISIC2018_Task1-2_Training_Data/truth/*.png\"))\n",
    "DATASET_SIZE = len(input_images)\n",
    "train_size = int(DATASET_SIZE * 0.7)\n",
    "val_size = test_size = int(DATASET_SIZE * 0.15)\n",
    "train_x = input_images[0:train_size]\n",
    "train_y = output_masks[0:train_size]\n",
    "test_x = input_images[train_size:train_size+test_size]\n",
    "test_y = output_masks[train_size:train_size+test_size]\n",
    "val_x = input_images[train_size+test_size:]\n",
    "val_y = output_masks[train_size+test_size:]\n",
    "\n",
    "\n",
    "\n",
    "def create_dataset(inputs, outputs):\n",
    "    ds  = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
    "    ds = ds.map(process_path)\n",
    "    ds = ds.map(resize_images)\n",
    "    return ds\n",
    "\n",
    "def plot_image(ds):\n",
    "    for image, mask in ds.take(1):\n",
    "#     print(np.unique(image))\n",
    "        print(np.unique(mask))\n",
    "        print(image.shape)\n",
    "        print(mask.shape)\n",
    "    #image = tf.image.resize(image, (1000, 1512, 1))\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "        plt.figure()\n",
    "        plt.imshow(mask[:,:,0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_7:0\", shape=(None, 256, 256, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "train_ds = create_dataset(train_x, train_y)\n",
    "test_ds = create_dataset(test_x, test_y)\n",
    "val_ds = create_dataset(val_x, val_y)\n",
    "model = improved_unet(HEIGHT, WIDTH)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 50 steps, validate for 20 steps\n",
      "Epoch 1/50\n",
      "50/50 [==============================] - 2s 41ms/step - loss: 2.7878 - acc: 0.6462 - val_loss: 0.6253 - val_acc: 0.6796\n",
      "Epoch 2/50\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.5065 - acc: 0.7925 - val_loss: 0.5112 - val_acc: 0.6858\n",
      "Epoch 3/50\n",
      "50/50 [==============================] - 6s 118ms/step - loss: 0.4175 - acc: 0.8240 - val_loss: 0.5644 - val_acc: 0.6743\n",
      "Epoch 4/50\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.4335 - acc: 0.8169 - val_loss: 0.4552 - val_acc: 0.8020\n",
      "Epoch 5/50\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.4215 - acc: 0.8123 - val_loss: 0.7319 - val_acc: 0.5256\n",
      "Epoch 6/50\n",
      "50/50 [==============================] - 5s 107ms/step - loss: 0.4674 - acc: 0.7774 - val_loss: 0.4744 - val_acc: 0.7637\n",
      "Epoch 7/50\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3918 - acc: 0.8546 - val_loss: 0.9163 - val_acc: 0.5986\n",
      "Epoch 8/50\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.3490 - acc: 0.8761 - val_loss: 0.8470 - val_acc: 0.6709\n",
      "Epoch 9/50\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.2090 - acc: 0.9272 - val_loss: 0.6540 - val_acc: 0.7428\n",
      "Epoch 10/50\n",
      "50/50 [==============================] - 2s 44ms/step - loss: 0.4061 - acc: 0.8411 - val_loss: 0.8383 - val_acc: 0.7184\n",
      "Epoch 11/50\n",
      "50/50 [==============================] - 3s 57ms/step - loss: 0.2037 - acc: 0.9299 - val_loss: 0.6362 - val_acc: 0.6856\n",
      "Epoch 12/50\n",
      "50/50 [==============================] - 2s 49ms/step - loss: 0.1932 - acc: 0.9271 - val_loss: 0.5635 - val_acc: 0.7604\n",
      "Epoch 13/50\n",
      "50/50 [==============================] - 6s 111ms/step - loss: 0.1744 - acc: 0.9288 - val_loss: 0.5534 - val_acc: 0.7170\n",
      "Epoch 14/50\n",
      "50/50 [==============================] - 3s 63ms/step - loss: 0.3949 - acc: 0.8682 - val_loss: 0.4822 - val_acc: 0.7349\n",
      "Epoch 15/50\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.4280 - acc: 0.8353 - val_loss: 0.6514 - val_acc: 0.6322A: 0s - loss: 0.4062 - acc: 0.\n",
      "Epoch 16/50\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.4842 - acc: 0.7964 - val_loss: 0.6112 - val_acc: 0.6736\n",
      "Epoch 17/50\n",
      "50/50 [==============================] - 3s 51ms/step - loss: 0.4347 - acc: 0.8395 - val_loss: 0.5502 - val_acc: 0.7061\n",
      "Epoch 18/50\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.4981 - acc: 0.7616 - val_loss: 0.6913 - val_acc: 0.6407\n",
      "Epoch 19/50\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.4181 - acc: 0.8303 - val_loss: 0.5712 - val_acc: 0.7098\n",
      "Epoch 20/50\n",
      "50/50 [==============================] - 3s 55ms/step - loss: 0.4356 - acc: 0.8232 - val_loss: 1.0497 - val_acc: 0.6690\n",
      "Epoch 21/50\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.5036 - acc: 0.7786 - val_loss: 0.7305 - val_acc: 0.6119\n",
      "Epoch 22/50\n",
      "50/50 [==============================] - 2s 40ms/step - loss: 0.4069 - acc: 0.8205 - val_loss: 0.4793 - val_acc: 0.7486\n",
      "Epoch 23/50\n",
      "50/50 [==============================] - 2s 39ms/step - loss: 0.4310 - acc: 0.8184 - val_loss: 1.0999 - val_acc: 0.6556\n",
      "Epoch 24/50\n",
      "50/50 [==============================] - 2s 45ms/step - loss: 0.4232 - acc: 0.8300 - val_loss: 0.5330 - val_acc: 0.7753\n",
      "Epoch 25/50\n",
      "50/50 [==============================] - 9s 182ms/step - loss: 0.2479 - acc: 0.9162 - val_loss: 0.5390 - val_acc: 0.7358\n",
      "Epoch 26/50\n",
      "50/50 [==============================] - 3s 62ms/step - loss: 0.2957 - acc: 0.9047 - val_loss: 0.5026 - val_acc: 0.7820\n",
      "Epoch 27/50\n",
      "50/50 [==============================] - 3s 55ms/step - loss: 0.2672 - acc: 0.9237 - val_loss: 0.6270 - val_acc: 0.7585\n",
      "Epoch 28/50\n",
      "50/50 [==============================] - 2s 43ms/step - loss: 0.1350 - acc: 0.9629 - val_loss: 0.5989 - val_acc: 0.7718\n",
      "Epoch 29/50\n",
      "50/50 [==============================] - 2s 47ms/step - loss: 0.2979 - acc: 0.9081 - val_loss: 0.4561 - val_acc: 0.7923\n",
      "Epoch 30/50\n",
      "50/50 [==============================] - 2s 49ms/step - loss: 0.1507 - acc: 0.9588 - val_loss: 0.5048 - val_acc: 0.8003\n",
      "Epoch 31/50\n",
      "50/50 [==============================] - 2s 49ms/step - loss: 0.2563 - acc: 0.9215 - val_loss: 0.4837 - val_acc: 0.8006\n",
      "Epoch 32/50\n",
      "50/50 [==============================] - 3s 55ms/step - loss: 0.1839 - acc: 0.9505 - val_loss: 0.6919 - val_acc: 0.7777\n",
      "Epoch 33/50\n",
      "50/50 [==============================] - 4s 78ms/step - loss: 0.2671 - acc: 0.9217 - val_loss: 0.4709 - val_acc: 0.8010\n",
      "Epoch 34/50\n",
      "50/50 [==============================] - 3s 56ms/step - loss: 0.2328 - acc: 0.9226 - val_loss: 0.7211 - val_acc: 0.7850\n",
      "Epoch 35/50\n",
      "50/50 [==============================] - 14s 272ms/step - loss: 0.3162 - acc: 0.8950 - val_loss: 0.5042 - val_acc: 0.7805\n",
      "Epoch 36/50\n",
      "50/50 [==============================] - 6s 122ms/step - loss: 0.2898 - acc: 0.9061 - val_loss: 0.4793 - val_acc: 0.7832\n",
      "Epoch 37/50\n",
      "15/50 [========>.....................] - ETA: 3s - loss: 0.2952 - acc: 0.9174WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2500 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs = 50, steps_per_epoch=50, validation_data = val_ds, validation_steps=20, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389/389 [==============================] - 28s 73ms/step - loss: 0.3958 - acc: 0.8585\n",
      "[0.39576435195890214, 0.8585277]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_ds)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389, 256, 256, 1)\n",
      "(389, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)\n",
    "true_masks = []\n",
    "for x, y in test_ds:\n",
    "    true_masks.append(y[0,:,:,:])\n",
    "true_masks = np.array(true_masks)\n",
    "print(true_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8585278430144401\n"
     ]
    }
   ],
   "source": [
    "pred_labels = np.round(predictions)\n",
    "pre_labels = pred_labels.flatten()\n",
    "coe = 2 * sum(pre_labels == true_masks.flatten())/(2*len(labels))\n",
    "print(coe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-66765ed864f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcoe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtest_masks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1.8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
