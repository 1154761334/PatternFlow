{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, backend\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet():\n",
    "    inputs = tf.keras.Input(shape=(256, 256, 4), name=\"img\")\n",
    "\n",
    "    # 3x3x3 conv\n",
    "    precontext1 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "\n",
    "    # context module 1 \n",
    "    # context module = conv2d 3x3x3 + droput(0.3) + conv2d 3x3x3\n",
    "    context1 = tf.keras.layers.BatchNormalization()(precontext1)\n",
    "    context1 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", padding=\"same\")(context1)\n",
    "    context1 = tf.keras.layers.Dropout(0.3)(context1)\n",
    "    context1 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", padding=\"same\")(context1)\n",
    "    # context1 = tf.keras.layers.LeakyReLU(alpha=0.1)(context1)\n",
    "\n",
    "\n",
    "    # combine pre-context and post-context\n",
    "    net1 = tf.keras.layers.Add()([precontext1, context1])\n",
    "    copy1 = net1\n",
    "\n",
    "    # downsample 1 using stride instead of max2d\n",
    "    precontext2 = tf.keras.layers.BatchNormalization()(net1)\n",
    "    precontext2 = tf.keras.layers.Conv2D(32, (3,3), strides=(2,2), activation=\"relu\", padding=\"same\")(precontext2)\n",
    "    # precontext2 = tf.keras.layers.LeakyReLU(alpha=0.1)(precontext2)\n",
    "\n",
    "\n",
    "    # context module 2 \n",
    "    # context module = conv2d 3x3x3 + droput(0.3) + conv2d 3x3x3\n",
    "    context2 = tf.keras.layers.BatchNormalization()(precontext2)\n",
    "    context2 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(context2)\n",
    "    context2 = tf.keras.layers.Dropout(0.3)(context2)\n",
    "    context2 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(context2)\n",
    "    # context2 = tf.keras.layers.LeakyReLU(alpha=0.1)(context2)\n",
    "\n",
    "\n",
    "\n",
    "    # combine pre-context and post-context\n",
    "    net2 = tf.keras.layers.Add()([precontext2, context2])\n",
    "    copy2 = net2\n",
    "\n",
    "    # downsample 2 using stride instead of max2d\n",
    "    precontext3 = tf.keras.layers.BatchNormalization()(net2)\n",
    "    precontext3 = tf.keras.layers.Conv2D(64, (3,3), strides=(2,2), activation=\"relu\", padding=\"same\")(precontext3)\n",
    "    # precontext3 = tf.keras.layers.LeakyReLU(alpha=0.1)(precontext3)\n",
    "\n",
    "    # context module 3\n",
    "    # context module = conv2d 3x3x3 + droput(0.3) + conv2d 3x3x3\n",
    "    context3 = tf.keras.layers.BatchNormalization()(precontext3)\n",
    "    context3 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(context3)\n",
    "    context3 = tf.keras.layers.Dropout(0.3)(context3)\n",
    "    context3 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(context3)\n",
    "    context3 = tf.keras.layers.LeakyReLU(alpha=0.1)(context3)\n",
    "\n",
    "\n",
    "\n",
    "    # combine pre-context and post-context\n",
    "    net3 = tf.keras.layers.Add()([precontext3, context3])\n",
    "    copy3 = net3\n",
    "\n",
    "\n",
    "    # downsample 3 using stride instead of max2d\n",
    "    precontext4 = tf.keras.layers.BatchNormalization()(net3)\n",
    "    precontext4 = tf.keras.layers.Conv2D(128, (3,3), strides=(2,2), activation=\"relu\", padding=\"same\")(precontext4)\n",
    "    # precontext4 = tf.keras.layers.LeakyReLU(alpha=0.1)(precontext4)\n",
    "\n",
    "\n",
    "\n",
    "    # context module 4\n",
    "    # context module = conv2d 3x3x3 + droput(0.3) + conv2d 3x3x3\n",
    "    context4 = tf.keras.layers.BatchNormalization()(precontext4)\n",
    "    context4 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(context4)\n",
    "    context4 = tf.keras.layers.Dropout(0.3)(context4)\n",
    "    context4 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(context4)\n",
    "    # context4 = tf.keras.layers.LeakyReLU(alpha=0.1)(context4)\n",
    "\n",
    "\n",
    "\n",
    "    # combine pre-context and post-context\n",
    "    net4 = tf.keras.layers.Add()([precontext4, context4])\n",
    "    copy4 = net4\n",
    "\n",
    "    # downsample 4 using stride instead of max2d\n",
    "    precontext5 = tf.keras.layers.BatchNormalization()(net4)\n",
    "    precontext5 = tf.keras.layers.Conv2D(256, (3,3), strides=(2,2), activation=\"relu\", padding=\"same\")(precontext5)\n",
    "    # precontext5 = tf.keras.layers.LeakyReLU(alpha=0.1)(precontext5)\n",
    "\n",
    "\n",
    "\n",
    "    # context module 5\n",
    "    # context module = conv2d 3x3x3 + droput(0.3) + conv2d 3x3x3\n",
    "    context5 = tf.keras.layers.BatchNormalization()(precontext5)\n",
    "    context5 = tf.keras.layers.Conv2D(256, (3,3), activation=\"relu\", padding=\"same\")(context5)\n",
    "    context5 = tf.keras.layers.Dropout(0.3)(context5)\n",
    "    context5 = tf.keras.layers.Conv2D(256, (3,3), activation=\"relu\", padding=\"same\")(context5)\n",
    "    context5 = tf.keras.layers.LeakyReLU(alpha=0.1)(context5)\n",
    "\n",
    "\n",
    "\n",
    "    # combine pre-context and post-context\n",
    "    net5 = tf.keras.layers.Add()([precontext5, context5])\n",
    "\n",
    "    # upsample 1\n",
    "    # upsample module = upsample2d + conv2d\n",
    "    upsample1 = tf.keras.layers.UpSampling2D()(net5)\n",
    "    upsample1 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(upsample1)\n",
    "    # upsample1 = tf.keras.layers.LeakyReLU(alpha=0.1)(upsample1)\n",
    "\n",
    "\n",
    "    # concat copy4 and upsample1\n",
    "    prelocal1 = tf.keras.layers.concatenate([copy4, upsample1])\n",
    "\n",
    "\n",
    "    # localization module 1\n",
    "    # localization module = conv2d 3x3x3 + conv2d 1x1x1\n",
    "    local1 = tf.keras.layers.BatchNormalization()(prelocal1)\n",
    "    local1 = tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(local1)\n",
    "    local1 = tf.keras.layers.Conv2D(128, (1,1), activation=\"relu\", padding=\"same\")(local1)\n",
    "    # local1 = tf.keras.layers.LeakyReLU(alpha=0.01)(local1)\n",
    "\n",
    "    # upsample 2\n",
    "    # upsample module = upsample2d + conv2d\n",
    "    upsample2 = tf.keras.layers.UpSampling2D()(local1)\n",
    "    upsample2 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(upsample2)\n",
    "    # upsample2 = tf.keras.layers.LeakyReLU(alpha=0.01)(upsample2)\n",
    "\n",
    "\n",
    "    # concat copy3 and upsample2\n",
    "    prelocal2 = tf.keras.layers.concatenate([copy3, upsample2])\n",
    "\n",
    "\n",
    "    # localization module 2\n",
    "    # localization module = conv2d 3x3x3 + conv2d 1x1x1\n",
    "    local2 = tf.keras.layers.BatchNormalization()(prelocal2)\n",
    "    local2 = tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(local2)\n",
    "    local2 = tf.keras.layers.Conv2D(64, (1,1), activation=\"relu\", padding=\"same\")(local2)\n",
    "    local2 = tf.keras.layers.LeakyReLU(alpha=0.01)(local2)\n",
    "\n",
    "\n",
    "    # segmentation 1/upscale\n",
    "    seg1 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(local2)\n",
    "    seg1 = tf.keras.layers.UpSampling2D()(seg1)\n",
    "\n",
    "\n",
    "    # upsample 3\n",
    "    # upsample module = upsample2d + conv2d\n",
    "    upsample3 = tf.keras.layers.UpSampling2D()(local2)\n",
    "    upsample3 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(upsample3)\n",
    "    # upsample3 = tf.keras.layers.LeakyReLU(alpha=0.01)(upsample3)\n",
    "\n",
    "\n",
    "    # concat copy2 and upsample3\n",
    "    prelocal3 = tf.keras.layers.concatenate([copy2, upsample3])\n",
    "\n",
    "\n",
    "    # localization module 3\n",
    "    # localization module = conv2d 3x3x3 + conv2d 1x1x1\n",
    "    local3 = tf.keras.layers.BatchNormalization()(prelocal3)\n",
    "    local3 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(local3)\n",
    "    local3 = tf.keras.layers.Conv2D(32, (1,1), activation=\"relu\", padding=\"same\")(local3)\n",
    "    # local3 = tf.keras.layers.LeakyReLU(alpha=0.01)(local3)\n",
    "\n",
    "\n",
    "\n",
    "    # segmentation 2/upscale\n",
    "    seg2 = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(local3)\n",
    "    # seg2 = tf.keras.layers.UpSampling2D()(seg2)\n",
    "\n",
    "\n",
    "    # combine seg1 and seg2\n",
    "    seg1_2 = tf.keras.layers.Add()([seg1, seg2])\n",
    "    seg1_2 = tf.keras.layers.UpSampling2D()(seg1_2)\n",
    "\n",
    "\n",
    "\n",
    "    # upsample 4\n",
    "    # upsample module = upsample2d + conv2d\n",
    "    upsample4 = tf.keras.layers.UpSampling2D()(local3)\n",
    "    upsample4 = tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", padding=\"same\")(upsample4)\n",
    "    # upsample4 = tf.keras.layers.LeakyReLU(alpha=0.01)(upsample4)\n",
    "\n",
    "\n",
    "    # concat copy1 and upsample4\n",
    "    pre_final = tf.keras.layers.concatenate([copy1, upsample4])\n",
    "    pre_final = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(pre_final)\n",
    "\n",
    "\n",
    "    # segmentation 3\n",
    "    pre_final = tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(pre_final)\n",
    "    seg_final = tf.keras.layers.Add()([pre_final, seg1_2])\n",
    "\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(4, 1, activation=\"softmax\")(seg_final)\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"unet\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1.0):\n",
    "    y_true_f = tf.keras.backend.batch_flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.batch_flatten(y_pred)\n",
    "\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    sums = tf.keras.backend.sum(tf.keras.backend.square(y_true_f)) + tf.keras.backend.sum(tf.keras.backend.square(y_pred_f))\n",
    "\n",
    "    return (2.0 * intersection + smooth) / (sums + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_palette(img):\n",
    "    list0 = get_arr_list(img)\n",
    "    palette = get_palette(list0)\n",
    "    return palette\n",
    "\n",
    "# img.shape = (256,256,4)\n",
    "def get_arr_list(img):\n",
    "    list0= []\n",
    "    for i in range(256):\n",
    "        for j in range(256):\n",
    "            list0.append(img[i,j,:].tolist())\n",
    "    return list0\n",
    "\n",
    "def uniq(lst):\n",
    "    last = object()\n",
    "    for item in lst:\n",
    "        if item == last:\n",
    "            continue\n",
    "        yield item\n",
    "        last = item\n",
    "\n",
    "\n",
    "def sort_and_deduplicate(l):\n",
    "    return list(uniq(sorted(l, reverse=True)))\n",
    "\n",
    "def get_palette(lst):\n",
    "    palette = sort_and_deduplicate(lst)\n",
    "    return palette\n",
    "\n",
    "def decode_img(img):\n",
    "    img = tf.image.decode_png(img, channels=4) #color images\n",
    "#     img / 255.0\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    #convert unit8 tensor to floats in the [0,1]range\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) \n",
    "    #resize the image into 32*32 \n",
    "    \n",
    "\n",
    "def ohm(palette, img):\n",
    "    one_hot_map = []\n",
    "    for colour in palette:\n",
    "        class_map = tf.reduce_all(tf.equal(img, colour), axis=-1)\n",
    "        one_hot_map.append(class_map)\n",
    "    one_hot_map = tf.stack(one_hot_map, axis=-1)\n",
    "    one_hot_map = tf.cast(one_hot_map, tf.float32)\n",
    "    return one_hot_map\n",
    "\n",
    "\n",
    "#  both paths are to an image\n",
    "def map_fn(image_path, label_path):\n",
    "    # Load the raw data from the file as a string.\n",
    "    img = tf.io.read_file(image_path)\n",
    "    # Convert the compressed string to a 3D uint8 tensor.\n",
    "    img = tf.image.decode_png(img, channels=4) # channels=3 for RGB, channels=1 for grayscale\n",
    "    # Resize the image to the desired size.\n",
    "    img = tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) \n",
    "    # Standardise values to be in the [0, 1] range.\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    # One-hot encode the label.\n",
    "    label1 = tf.io.read_file(label_path)\n",
    "    label2 = decode_img(label1)\n",
    "    one_hot = ohm(palette, label2)\n",
    "    # Return the processed image and label.\n",
    "    return img, one_hot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
